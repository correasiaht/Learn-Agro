# -*- coding: utf-8 -*-
"""Learn + Agro

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HmGzUlAldmouWeZzPP2QYl40ubxp2uaU
"""

!pip install selenium

!pip install webdriver-manager

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
chrome_options = Options ()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome(options=chrome_options)

driver.get('https://www.asbraap.org/index.php?page=empresas')

with open ("arquivo.xml", "w") as arq:
  arq.write(driver.page_source)

driver.quit()

!pip install beautifulsoup4

from bs4 import BeautifulSoup

arquivoXML = open('arquivo.xml', 'r')

soup = BeautifulSoup(arquivoXML.read(), 'html.parser')
arquivoXML.close()

nomesEmpresas = soup.find_all('h2')

Empresas = []
for nome in nomesEmpresas:
  #print(nome.text,'\n')
  Empresas.append(nome.text)
for nome in Empresas:
  print(nome,'\n')

linksEmpresas = soup.find_all('h4')

links =[]
qtdeEmp = len(Empresas)
for i in range(qtdeEmp):
  #print(nome.a ['href'],'\n')
  links.append(linksEmpresas[i].a ['href'])

for nome in links:
  print(nome, '\n')

import csv
import pandas as pd

dados =[Empresas, links]

with open('dados.csv', 'w', newline='', encoding='utf-8') as arquivo_csv:
  escritor = csv.writer(arquivo_csv)
  for linha in dados:
      escritor.writerow(linha)

x = []
for i in zip(Empresas, links): #junta as duas listas j√° transpostas
    x.append(i)

colunas = ['Empresas',    'Links']
df_dados = pd.DataFrame(x, columns = colunas) #cria um dataframe com elas
display(df_dados) #exibe ele

df_dados.to_csv('dados.csv',index=False) #grava o arquivo

print(soup.title.string)